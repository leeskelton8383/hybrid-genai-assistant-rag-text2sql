{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82d17614",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8842fbae",
   "metadata": {},
   "source": [
    "1. Load and Chunk the wikipedia narrative docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e32198d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example Chunks (JSON) ---\n",
      "{\n",
      "  \"chunk_id\": \"2020_philadelphia_eagles_season_001\",\n",
      "  \"doc_title\": \"2020_philadelphia_eagles_season\",\n",
      "  \"text\": \"The 2020 season was the Philadelphia Eagles' 88th in the National Football League (NFL) and their fifth and final under head coach Doug Pederson. They failed to improve on their 9\\u20137 record from the previous season following a 23\\u201317 loss to the Seattle Seahawks in Week 12. They were eliminated from playoff contention for the first time since 2016 following a Week 16 loss to the Dallas Cowboys and finished with a dismal 4\\u201311\\u20131 record, the second-worst in the National Football Conference (NFC), and their worst since 2012. After starting 3\\u20134\\u20131 heading into their bye week and leading the NFC East, the Eagles would lose 7 of their last 8 games. Injuries and poor quarterback play were factors in their struggles in the season. On January 11, 2021, the Eagles announced head coach Doug Pederson would not return after the season, as he was dismissed the same day. For the first time since 1998, the Eagles failed to score 30 or more points in a single game the entire season. Their .281 winning percentage was their worst since 2012. Overall, Carson Wentz, statistically, had one of the poorest seasons by a quarterback in franchise history, throwing for 2,620 yards, 16 touchdowns, 15 interceptions, and completed just 57.4% of his passes (251 for 437) to go with his 72.8 passer rating. He also got sacked 50 times for 326 yards. On July 14, 2020, the city of Philadelphia placed a ban on large events for six months, meaning that the Eagles' home games would have no fans in attendance. However, starting in week 6, Philadelphia Mayor Jim Kenney announced that the city would allow 7,500 fans to attend Eagles home games. This was reversed on November 16, 2020, as the city of Philadelphia implemented outdoor restrictions. The season also marked the\"\n",
      "}\n",
      "{\n",
      "  \"chunk_id\": \"2020_philadelphia_eagles_season_002\",\n",
      "  \"doc_title\": \"2020_philadelphia_eagles_season\",\n",
      "  \"text\": \"home games would have no fans in attendance. However, starting in week 6, Philadelphia Mayor Jim Kenney announced that the city would allow 7,500 fans to attend Eagles home games. This was reversed on November 16, 2020, as the city of Philadelphia implemented outdoor restrictions. The season also marked the end of the Carson Wentz era in Philadelphia as he was traded to the Indianapolis Colts in the 2021 off-season. As of the 2024 season, this is the most recent season the Eagles missed the playoffs, finished with a losing record, and finished in last place in the NFC East. Roster changes Free agents Signings Departures Trades March 19: The Eagles traded a third-round pick in the 2020 NFL draft and a fifth-round pick in the 2020 NFL draft to the Detroit Lions for CB Darius Slay. April 25: The Eagles traded their sixth-round pick in the 2020 NFL draft, 190th overall, to the San Francisco 49ers for their sixth-round pick, 210th overall, and Marquise Goodwin Draft Notes The Eagles acquired one additional seventh-round selection, along with wide receiver DeSean Jackson, in a trade that sent their 2019 sixth-round selection to the Tampa Bay Buccaneers. However, the Eagles made trades with the Atlanta Falcons and the New England Patriots involving both their own seventh-round selection and the one acquired from the Buccaneers. The Eagles acquired an additional fifth-round selection in a trade that sent one of their seventh-round selections and defensive end Michael Bennett to the Patriots. The Eagles acquired an additional sixth-round selection, along with linebacker Duke Riley, in a trade that sent one of their seventh-round selections and safety Johnathan Cyprien to the Falcons. The Eagles traded a sixth-round selection to the Chicago Bears in exchange for running back Jordan Howard. As the result of the negative differential\"\n",
      "}\n",
      "{\n",
      "  \"chunk_id\": \"2020_philadelphia_eagles_season_003\",\n",
      "  \"doc_title\": \"2020_philadelphia_eagles_season\",\n",
      "  \"text\": \"an additional sixth-round selection, along with linebacker Duke Riley, in a trade that sent one of their seventh-round selections and safety Johnathan Cyprien to the Falcons. The Eagles traded a sixth-round selection to the Chicago Bears in exchange for running back Jordan Howard. As the result of the negative differential of free agent signings and departures that the Eagles experienced during the first wave of the 2019 free agency period, the team is projected to receive two compensatory selections for the 2020 draft. Free agent transactions that occurred after May 7, 2019, did not factor into the team's formula for determining compensatory selections. The Eagles traded a third-round and fifth-round selection in the 2020 NFL draft to the Detroit Lions for cornerback Darius Slay. Staff Final roster Preseason The Eagles' preseason schedule was announced on May 7, but was later cancelled due to the COVID-19 pandemic. Regular season Schedule The Eagles' 2020 schedule was announced on May 7. Note: Intra-division opponents are in bold text. Game summaries Week 1: at Washington Football Team In a near-reversal of the previous season's opener, the Eagles scored the first 17 points, only for the Washington Football Team to then shut their offense out for the remainder of the afternoon. Meanwhile, Washington's offense scored 27 unanswered points, and the defense sacked Carson Wentz eight times, recorded two interceptions, and forced three fumbles. With the loss, Philadelphia's six-game winning streak against Washington dating back to 2016 came to an end, and the Eagles lost the first game of the season for the first time since 2015. Week 2: vs. Los Angeles Rams The Eagles' struggles continued in their home opener against the Los Angeles Rams. An early fumble by Miles Sanders led to a Rams touchdown by Tyler Higbee. After the Eagles cut their deficit\"\n",
      "}\n",
      "\n",
      "‚úÖ Saved 160 chunks to c:\\Users\\250331\\OneDrive - MyFedEx\\Documents\\Python Scripts\\EaglesGPT\\data\\chunks.jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# -----------------------------------\n",
    "# Step 1: Chunking Function (~300 words with overlap)\n",
    "# -----------------------------------\n",
    "def chunk_text_fixed(text, chunk_size=300, overlap=50):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = \" \".join(words[i:i+chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# -----------------------------------\n",
    "# Step 2: Main Load + Chunk + Print + Save Function\n",
    "# -----------------------------------\n",
    "def load_and_chunk_wikipedia(folder_path, output_path, chunk_size=300, overlap=50):\n",
    "    all_chunks = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "                doc_title = filename.replace('.txt', '')\n",
    "\n",
    "                chunks = chunk_text_fixed(text, chunk_size=chunk_size, overlap=overlap)\n",
    "\n",
    "                for i, chunk in enumerate(chunks):\n",
    "                    chunk_id = f\"{doc_title}_{str(i+1).zfill(3)}\"\n",
    "                    all_chunks.append({\n",
    "                        'chunk_id': chunk_id,\n",
    "                        'doc_title': doc_title,\n",
    "                        'text': chunk\n",
    "                    })\n",
    "\n",
    "    # --- Print First 3 Chunks as JSON ---\n",
    "    print(\"\\n--- Example Chunks (JSON) ---\")\n",
    "    for chunk in all_chunks[:3]:\n",
    "        print(json.dumps(chunk, indent=2))\n",
    "\n",
    "    # --- Save All Chunks to JSONL ---\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with open(output_path, 'w', encoding='utf-8') as out_file:\n",
    "        for chunk in all_chunks:\n",
    "            out_file.write(json.dumps(chunk) + '\\n')\n",
    "\n",
    "    print(f\"\\n‚úÖ Saved {len(all_chunks)} chunks to {output_path}\")\n",
    "\n",
    "    return all_chunks\n",
    "\n",
    "\n",
    "# -----------------------------------\n",
    "# Step 3: Setup Clean Project Paths (portable)\n",
    "# -----------------------------------\n",
    "# Assumes notebook is in /notebooks and data is in /data/narratives\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(NOTEBOOK_DIR, '..'))\n",
    "NARRATIVE_DIR = os.path.join(PROJECT_ROOT, 'data', 'narratives')\n",
    "CHUNKS_OUT_PATH = os.path.join(PROJECT_ROOT, 'data', 'chunks.jsonl')\n",
    "\n",
    "# --- Run It ---\n",
    "chunks = load_and_chunk_wikipedia(folder_path=NARRATIVE_DIR, output_path=CHUNKS_OUT_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6a3d07",
   "metadata": {},
   "source": [
    "2. Embed the corpus and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bdb1c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/chunks.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-260011534.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Run It All\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# -----------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_chunks_from_jsonl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHUNKS_JSONL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0membedded_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mbuild_faiss_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFAISS_INDEX_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMETADATA_JSON_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-260011534.py\u001b[0m in \u001b[0;36mload_chunks_from_jsonl\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_chunks_from_jsonl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mchunks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/chunks.jsonl'"
     ]
    }
   ],
   "source": [
    "#! pip install -U sentence-transformers\n",
    "#! pip install faiss-cpu\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "import requests\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------------\n",
    "# Path Setup (local)\n",
    "# -----------------------------------\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(NOTEBOOK_DIR))  # no \"..\" needed if running from root\n",
    "\n",
    "CHUNKS_JSONL_PATH = os.path.join(PROJECT_ROOT, 'data', 'chunks.jsonl')\n",
    "FAISS_INDEX_PATH = os.path.join(PROJECT_ROOT, 'data', 'narrative_index.faiss')\n",
    "METADATA_JSON_PATH = os.path.join(PROJECT_ROOT, 'data', 'narrative_metadata.json')\n",
    "\n",
    "# -----------------------------------\n",
    "# Load Chunks from JSONL\n",
    "# -----------------------------------\n",
    "def load_chunks_from_jsonl(filepath):\n",
    "    chunks = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            chunks.append(json.loads(line))\n",
    "    return chunks\n",
    "\n",
    "# -----------------------------------\n",
    "# Embed Chunks using Sentence-Transformers\n",
    "# -----------------------------------\n",
    "def embed_chunks(chunks, model_name='all-MiniLM-L6-v2'):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    texts = [chunk['text'] for chunk in chunks]\n",
    "    print(f\"üîÅ Embedding {len(texts)} chunks...\")\n",
    "    embeddings = model.encode(texts, show_progress_bar=True, batch_size=32)\n",
    "\n",
    "    for i, emb in enumerate(embeddings):\n",
    "        chunks[i]['embedding'] = emb.tolist()\n",
    "    return chunks\n",
    "\n",
    "# -----------------------------------\n",
    "# Build FAISS Index and Save Metadata\n",
    "# -----------------------------------\n",
    "def build_faiss_index(embedded_chunks, index_path, metadata_path):\n",
    "    embeddings = np.array([chunk['embedding'] for chunk in embedded_chunks]).astype('float32')\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "\n",
    "    os.makedirs(os.path.dirname(index_path), exist_ok=True)\n",
    "    faiss.write_index(index, index_path)\n",
    "    print(f\"‚úÖ FAISS index saved to {index_path}\")\n",
    "\n",
    "    metadata = [\n",
    "        {\n",
    "            'chunk_id': chunk['chunk_id'],\n",
    "            'doc_title': chunk['doc_title'],\n",
    "            'text': chunk['text']\n",
    "        }\n",
    "        for chunk in embedded_chunks\n",
    "    ]\n",
    "    with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    print(f\"‚úÖ Metadata saved to {metadata_path}\")\n",
    "\n",
    "# -----------------------------------\n",
    "# Retrieval Function\n",
    "# -----------------------------------\n",
    "def retrieve_narrative_chunks(question, index_path, metadata_path, model_name='all-MiniLM-L6-v2', top_k=3):\n",
    "    print(f\"üîç Retrieving top {top_k} chunks for question: {question}\")\n",
    "    \n",
    "    # Load FAISS index\n",
    "    index = faiss.read_index(index_path)\n",
    "    \n",
    "    # Load metadata\n",
    "    with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    # Embed the question\n",
    "    model = SentenceTransformer(model_name)\n",
    "    query_vector = model.encode([question]).astype('float32')\n",
    "\n",
    "    # Search FAISS\n",
    "    distances, indices = index.search(query_vector, top_k)\n",
    "    results = [metadata[i] for i in indices[0]]\n",
    "\n",
    "    print(\"\\nüìÑ Top Retrieved Chunks:\\n\")\n",
    "    for i, r in enumerate(results):\n",
    "        print(f\"[{i+1}] ({r['chunk_id']}) from {r['doc_title']}\")\n",
    "        print(r['text'][:500] + \"\\n---\\n\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# -----------------------------------\n",
    "# Use Ollama + Mistral to Answer\n",
    "# -----------------------------------\n",
    "def answer_with_mistral(question, retrieved_chunks):\n",
    "    context = \"\\n\\n\".join(chunk[\"text\"] for chunk in retrieved_chunks)\n",
    "\n",
    "    prompt = f\"\"\"Answer the question based on the following Eagles season narratives:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    response = requests.post(\n",
    "        \"http://localhost:11434/api/generate\",\n",
    "        json={\"model\": \"mistral\", \"prompt\": prompt}\n",
    "    )\n",
    "    output = response.json()[\"response\"]\n",
    "    print(\"\\nü§ñ Mistral's Answer:\\n\")\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "# -----------------------------------\n",
    "# Run It All\n",
    "# -----------------------------------\n",
    "if __name__ == '__main__':\n",
    "    chunks = load_chunks_from_jsonl(CHUNKS_JSONL_PATH)\n",
    "    embedded_chunks = embed_chunks(chunks)\n",
    "    build_faiss_index(embedded_chunks, index_path=FAISS_INDEX_PATH, metadata_path=METADATA_JSON_PATH)\n",
    "\n",
    "    # üîÅ Try a test query\n",
    "    question = \"What happened in the 2022 Eagles season?\"\n",
    "    retrieved = retrieve_narrative_chunks(question, FAISS_INDEX_PATH, METADATA_JSON_PATH)\n",
    "\n",
    "    # üß† Let Mistral answer\n",
    "    answer_with_mistral(question, retrieved)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
